{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa423f1-42a5-4039-babd-6a367bc8df5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e705554-3ac1-4870-afe7-375383cb8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba76eb97-3e5e-464c-b8b2-34824f54ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocess as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce9b3e-3f0a-4539-a3c0-bff77b6b35a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Read data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6877e3-3d2a-47f1-ac46-c1f909265ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.read_csv('./Data/glioblastoma_BT_S2/ref.csv', index_col = 0)\n",
    "df_alt = pd.read_csv('./Data/glioblastoma_BT_S2/alt.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c578e5-dadf-49aa-ac69-dba3c5a916d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multi-index for easier handling of the data\n",
    "df_ref['chromosome'] = [locus.split('_')[0] for locus in df_ref.index]\n",
    "df_ref['locus'] = [locus.split('_')[1] for locus in df_ref.index]\n",
    "df_ref = df_ref.set_index(['chromosome', 'locus'])\n",
    "\n",
    "df_alt['chromosome'] = [locus.split('_')[0] for locus in df_alt.index]\n",
    "df_alt['locus'] = [locus.split('_')[1] for locus in df_alt.index]\n",
    "df_alt = df_alt.set_index(['chromosome', 'locus'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20256990-cec3-4aa7-b1ba-123e1a188cd9",
   "metadata": {},
   "source": [
    "def heterozygosity_map(chromosome, save = False):\n",
    "    ref = np.array(df_ref.loc[chromosome,:])\n",
    "    alt = np.array(df_alt.loc[chromosome,:])\n",
    "    \n",
    "    ref_proportion = (ref + 1) / (ref + alt + 2) # add a dummy count to both ref and alt to avoid division by 0\n",
    "    alpha = 2 * np.arctan(ref + alt) / np.pi # hide loci without enough counts\n",
    "    \n",
    "    plt.figure(figsize=(24,16))\n",
    "    plt.imshow(ref_proportion.T, cmap = 'viridis', vmin = 0., vmax = 1., alpha = alpha.T) \n",
    "    # \"viridis\": yellow for 1, purple for 0, green/blue for 0.5 (https://matplotlib.org/3.5.1/tutorials/colors/colormaps.html)\n",
    "    plt.title(chromosome, fontsize = 17)\n",
    "    plt.xlabel('locus index', fontsize = 17)\n",
    "    plt.ylabel('cell index', fontsize = 17)\n",
    "    if save: \n",
    "        plt.savefig('chromosome' + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4d58d17-0b66-49dd-bc63-a73f464e46f1",
   "metadata": {},
   "source": [
    "# proportion of entries that has at least one read (reference or alternative or both)\n",
    "np.sum(np.logical_or(np.array(df_ref), np.array(df_alt))) / df_ref.size\n",
    "# Conclustion: 70% of all entries have no read at all"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b265608-de43-40e4-ba28-fe01dab7de14",
   "metadata": {},
   "source": [
    "heterozygosity_map('chr1', save = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c410337-5bb1-433f-80b0-86e3c703cf6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "for chromosome in df_ref.index.get_level_values('chromosome').unique():\n",
    "    heterozygosity_map(chromosome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fc647-ab6e-4f91-b481-4bed4a3ddba8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b15f8c3e-d26d-4c86-84a8-77f9b97c3d22",
   "metadata": {},
   "source": [
    "# TODO: function overload to combine log_add and log_sum? \n",
    "# TODO: returns nan when both values are inf or -inf. Could this be a problem? \n",
    "\n",
    "def log_add(a, b): \n",
    "    if a > b: # a < b might result in overflow, hence case distinction\n",
    "        return a + np.log(1 + np.exp(b-a))\n",
    "    else: \n",
    "        return b + np.log(1 + np.exp(a-b))\n",
    "    # return max(a,b) + np.log(1 + np.exp(-abs(a - b))) # alternative implementation, seems to be slower\n",
    "    \n",
    "log_add_vec = np.vectorize(log_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6ac26-d66a-42d1-99fa-c1fecc8b0751",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data generator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5b6eaa6-b463-4eea-8afa-65ce107def9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "class DataGenerator: # todo: rewrite data generator\n",
    "    genotypes = ['R', 'A', 'H']\n",
    "    mutation_types = ['RR', 'AA', 'HH', 'RH', 'AH', 'HR', 'HA']\n",
    "    \n",
    "    def __init__(self, priors = np.ones(7) / 7, f = 0.95, omega = 100, omega_h = 50, coverage_sampler = None):\n",
    "        self.priors = priors\n",
    "        self.alpha = f * omega\n",
    "        self.beta = omega - self.alpha\n",
    "        self.omega_h = omega_h\n",
    "        if coverage_sampler is None: \n",
    "            self.coverage_sampler = lambda : poisson.rvs(mu = 8) # For testing purpose: sample coverage from Poisson distribution\n",
    "        else: \n",
    "            self.coverage_sampler = coverage_sampler\n",
    "    \n",
    "    @staticmethod\n",
    "    def n_mutation_prior(n, k): \n",
    "        # Pblm: float overflow, had to use long int (by setting exact = True) which seems to be slower\n",
    "        return sp.special.comb(n, k, exact = True) ** 2 / ((2*k-1) * sp.special.comb(2*n, 2*k, exact = True)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def random_genotypes(n, original, mutated):\n",
    "        genotypes = np.array([original for i in range(n)], dtype = str) \n",
    "        if original != mutated: \n",
    "            P_n_mutated = np.array([DataGenerator.n_mutation_prior(n, k) for k in range(1, n+1)])\n",
    "            n_mutated = np.random.choice(np.arange(1,n+1), p = P_n_mutated)\n",
    "            genotypes[np.random.choice(n, n_mutated, replace = False)] = mutated\n",
    "        return genotypes\n",
    "    \n",
    "    def generate_single_read(self, genotype, coverage): \n",
    "        if genotype == 'R': \n",
    "            n_ref = betabinom.rvs(coverage, self.alpha, self.beta)\n",
    "            n_alt = coverage - n_ref\n",
    "        elif genotype == 'A': \n",
    "            n_alt = betabinom.rvs(coverage, self.alpha, self.beta)\n",
    "            n_ref = coverage - n_alt\n",
    "        elif genotype == 'H': \n",
    "            n_ref = betabinom.rvs(coverage, self.omega_h / 2, self.omega_h / 2)\n",
    "            n_alt = coverage - n_ref\n",
    "        else: \n",
    "            print('[generate_single_read] ERROR: invalid genotype.')\n",
    "            return 0, 0\n",
    "        return n_ref, n_alt\n",
    "    \n",
    "    def generate_reads(self, n_loci = 1, n_cells = 100, mutations = None):\n",
    "        # if not provided, get random mutations\n",
    "        if mutations is None: \n",
    "            mutations = []\n",
    "            for i in range(n_loci):\n",
    "                mut_i = np.random.choice(DataGenerator.mutation_types)\n",
    "                mutations.append(mut_i)\n",
    "        else: \n",
    "            n_loci = len(mutations)\n",
    "        \n",
    "        result_ref = np.zeros((n_loci, n_cells))\n",
    "        result_alt = np.zeros((n_loci, n_cells))\n",
    "        \n",
    "        for i in range(n_loci):\n",
    "            genotypes = DataGenerator.random_genotypes(n_cells, mutations[i][0], mutations[i][1])\n",
    "            for j in range(n_cells):\n",
    "                coverage = self.coverage_sampler()\n",
    "                result_ref[i,j], result_alt[i,j] = self.generate_single_read(genotypes[j], coverage)\n",
    "        \n",
    "        if mutations is None: \n",
    "            return mutations, result_ref, result_alt\n",
    "        else: \n",
    "            return result_ref, result_alt # no need to return mutations if it is already provided as argument"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2a7022d-e306-4be5-9cb5-97170e344ffe",
   "metadata": {},
   "source": [
    "def coverage_sampler(): \n",
    "    return int(np.random.choice(coverages))\n",
    "dg = DataGenerator(coverage_sampler = coverage_sampler)\n",
    "ref_test, alt_test = dg.generate_reads(mutations = ['AH' for i in range(3)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f20f0bc-a319-4d1a-af6e-ca0154f750da",
   "metadata": {},
   "source": [
    "plt.figure(figsize = (24, 16))\n",
    "plt.hist(coverages, bins = 1000)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f830e4c-a725-4dd1-99dd-66b4ec5f3efa",
   "metadata": {},
   "source": [
    "### Mutation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f181fd2d-d8c1-42b9-9c2f-2650fa6b2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutation_detection import *\n",
    "from LOH_detection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b16604-9126-4fca-9050-88d84dd9352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = df_ref.to_numpy(dtype = float)\n",
    "alt = df_alt.to_numpy(dtype = float)\n",
    "coverages = ref.flatten() + alt.flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08ff1696-7ad4-4554-96b8-94f4bd94a8e6",
   "metadata": {},
   "source": [
    "def test_thread_numbers(max_n_threads, n_loci = 50):  \n",
    "    time_costs = np.zeros(max_n_threads)\n",
    "    for n in tqdm(range(1,max_n_threads+1)): \n",
    "        start_time = time.time()\n",
    "        get_posteriors(ref[0:n_loci,:], alt[0:n_loci,:], n_threads = n)\n",
    "        time_costs[n-1] = time.time() - start_time\n",
    "    \n",
    "    return time_costs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0abadad-f587-4857-83d0-3641f6b3e544",
   "metadata": {},
   "source": [
    "time_costs = test_thread_numbers(12)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(np.array(range(1, 13)), time_costs)\n",
    "plt.xlabel('number of threads')\n",
    "plt.ylabel('runtime (s)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99bb33b3-6272-4c98-8a72-9022845f030c",
   "metadata": {},
   "source": [
    "# expected runtime (in minutes) to run on the complete dataset\n",
    "time_costs[5] / 50 * ref.shape[0] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2859045-57b5-4a7f-9041-3fdf25cdaea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.37756068, -3.097773  , -4.3605863 , -4.90861448, -5.20414742,\n",
       "       -5.34459926, -5.35256743, -5.20710746, -4.81257143, -3.70868208,\n",
       "       -1.35180819, -3.70868208, -4.81257143, -5.20710746, -5.35256743,\n",
       "       -5.34459926, -5.20414742, -4.90861448, -4.3605863 , -3.097773  ,\n",
       "       -1.37756068])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_composition_priors(10, genotype_freq = {'R': 1/3, 'H': 1/3, 'A': 1/3}, mutation_rate = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cb5fd1-a07a-4768-8ac6-814afb902421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 33.48343937397003 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "posteriors = get_posteriors(ref, alt, n_threads = 6)\n",
    "print('Runtime:', (time.time() - start_time) / 60, 'min')\n",
    "pd.DataFrame(posteriors, columns = ['R', 'H', 'A', 'RH', 'HA'], index = df_ref.index).to_csv('./posteriors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b461ea-4d8a-433a-a56d-9396b221119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posteriors = pd.read_csv('./posteriors.csv', index_col = (0,1))\n",
    "posteriors = df_posteriors.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe71449-4746-478f-a0cf-850e443334b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_idx, mut_type_idx = np.where(posteriors[:,3:] > 1 - 1 / posteriors.shape[0])\n",
    "n_mutated = mutated_idx.size\n",
    "homos = [['R', 'A'][i] for i in mut_type_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b598086-bbf1-4948-863f-dd23a7367428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22426bbfbb764d3a935cdab7ac522944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb2f0f274e14dfc9436ffbe8a7ce8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_posteriors = get_corr_posteriors(ref[mutated_idx,:], alt[mutated_idx,:], homos, corr_prior = 1/2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090bf80e-5cb8-4e99-9973-592531e821bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = {'correlation posterior': np.concatenate((corr_posteriors, [0])), 'mutation type': ['H' + h for h in homos]}, \n",
    "             index = df_posteriors.index[mutated_idx]).to_csv('./corr_posteriors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc460d-0e95-4fe5-a03e-803f2e854952",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVD Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce20e03-3823-4bee-9ccd-b2c799d80721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: data matrix in which rows (dimension 0) are samples and columns (dimension 1) are features\n",
    "def mean_impute(X): \n",
    "    X_imputed = X.copy() \n",
    "    for i in range(X.shape[1]): \n",
    "        feature = X[:,i] \n",
    "        mean = np.nanmean(feature) # take mean of the feature, ignoring NaN\n",
    "        if np.isnan(mean): \n",
    "            print('[Mean Imputation] WARNING: Empty feature at column %d.'%i) \n",
    "        nan_indices = np.where(np.isnan(feature))[0] \n",
    "        X_imputed[nan_indices,i] = mean \n",
    "    return X_imputed \n",
    "\n",
    "\n",
    "def zero_impute(X): \n",
    "    X_imputed = X.copy()\n",
    "    X_imputed[np.isnan(X)] = 0\n",
    "    return X_imputed\n",
    "    \n",
    "\n",
    "def svd_impute(X, rank = None, tol = 0.1, max_iter = 100):\n",
    "    if rank is None: \n",
    "        rank = min(X.shape) // 2\n",
    "    \n",
    "    nan_indices = np.where(np.isnan(X))\n",
    "    X_imputed = zero_impute(X) #initialise all nan entries with the a mean imputation\n",
    "    \n",
    "    for i in tqdm(range(max_iter)):\n",
    "        X_old = X_imputed.copy()\n",
    "        L,D,R = np.linalg.svd(X_imputed)\n",
    "        X_approx = L[:,:rank] @ np.diag(D[:rank]) @ R[:rank,:] #rank r approximation of X_imputed\n",
    "        X_imputed[nan_indices] = X_approx[nan_indices]\n",
    "        fnorm = np.linalg.norm(X_old - X_imputed, ord=\"fro\")\n",
    "        if fnorm < tol:\n",
    "            print('[SVD Imputation]: Converged after %d iterations.'%(i+1))\n",
    "            print('Frobenius norm:', fnorm)\n",
    "            break\n",
    "        if (i+1) >= max_iter:\n",
    "            print('[SVD Imputation]: Maximum number (%d) of iterations reached.'%(i+1))\n",
    "            print('Frobenius norm:', fnorm)\n",
    "    \n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34437a62-d169-46c6-b755-f1940c89527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e61551-ddcb-43ab-96c7-c75c772953bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(alt > 5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9f927-6c90-4e05-8d23-d31be01a8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"darkgrid\"):\n",
    "    plt.figure(figsize = (16, 12))\n",
    "    plt.plot(np.sum(alt > 16, axis = 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566879f-330d-4d92-8563-9b3797b28955",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ref.shape[0]): \n",
    "    for j in range(ref.shape[1]): \n",
    "        if ref[i,j] == 0 and alt[i,j] == 0:\n",
    "            ref[i,j] = np.nan\n",
    "            alt[i,j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0eb3b-fca2-428c-b3f2-6680b1e2ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([ref, alt], axis = 1)\n",
    "X_imputed = svd_impute(X, rank = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993f947-f096-4068-9f90-ad691368a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86cf2a-424f-4f92-a092-1156242bc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_imputed = X_imputed[:,:ref.shape[1]]\n",
    "alt_imputed = X_imputed[:,ref.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f229ae4-39c7-4926-abb8-edca2ef94ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_proportion = (ref_imputed + 1) / (ref_imputed + alt_imputed + 2)\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.imshow(ref_proportion.T, cmap = 'viridis', vmin = 0., vmax = 1.) \n",
    "# \"viridis\": yellow for 1, purple for 0, green/blue for 0.5 (https://matplotlib.org/3.5.1/tutorials/colors/colormaps.html)\n",
    "plt.xlabel('locus index', fontsize = 17)\n",
    "plt.ylabel('cell index', fontsize = 17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a21f3-9096-41c9-b93c-8f992bf316e7",
   "metadata": {},
   "source": [
    "### HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf1e3f-fb05-41d0-a2f5-cfaaf984129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I: initial probability\n",
    "# T: transition probability (including the begin state)\n",
    "# E: emission probability\n",
    "# X: observation\n",
    "def viterbi(I, T, E, X):\n",
    "    length = X.shape[0]\n",
    "    n_states = X.shape[1]\n",
    "    v = np.zeros((length, n_states)) # v[j, k] = max joint probability having k at step j and emission X[i]\n",
    "    \n",
    "    v[0,:] = np.array([I[i] * E(i, X[0]) for i in range(n_states)])\n",
    "    for j in range(1, length):\n",
    "        for k in range(n_states):\n",
    "            v[j,k] = E(k, X[j]) * np.max([v[j-1,l] * T(l,k) for l in range(n_states)]) # l: assumed state of previous step\n",
    "    \n",
    "    best_path = np.argmax(v, axis = 1)\n",
    "    \n",
    "    return best_path, v[-1, best_path[-1]] # second return is the max joint probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09694a-7884-4463-8062-0700ed7102f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.array([[0.9, 0.1],\n",
    "                              [0.5, 0.5]])\n",
    "def T(pre, post):\n",
    "    return transition_matrix[pre, post]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6708b5-b751-44ca-9345-842247f8582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(state, obs, f = 0.7, omega = 10):\n",
    "    n_ref = obs[0]\n",
    "    coverage = np.sum(obs)\n",
    "    if state == 1: # normal (heterozygous)\n",
    "        alpha = (1/2 - 2/3 * f) / omega\n",
    "        beta = omega - alpha\n",
    "    elif state == 2: # LOH\n",
    "        alpha = f * omega\n",
    "        beta = omega - alpha\n",
    "    else: \n",
    "        print('\\n ERROR: invalid state \\n')\n",
    "        return\n",
    "    \n",
    "    return betabinom.pmf(n_ref, coverage, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba62b5-afca-4e2b-b10a-5b0cf5dae8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((np.array(df_ref.loc['chr1',:])[0,:], np.array(df_alt.loc['chr1',:])[0,:])).T\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
